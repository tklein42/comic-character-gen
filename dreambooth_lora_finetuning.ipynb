{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8gbg-7YZ4rs",
        "outputId": "24418999-4a2c-496d-c56f-4431b60b804f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 70781, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 70781 (delta 17), reused 21 (delta 9), pack-reused 70740 (from 1)\u001b[K\n",
            "Receiving objects: 100% (70781/70781), 49.66 MiB | 16.64 MiB/s, done.\n",
            "Resolving deltas: 100% (52282/52282), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/diffusers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "xUIPWJKhaegN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directories for storing data\n",
        "# This is for colab environment\n",
        "os.makedirs(\"character\", exist_ok=True)\n",
        "os.makedirs(\"character/data\", exist_ok=True) # Images of Character\n",
        "os.makedirs(\"character/checkpoint\", exist_ok=True) # Where Checkpoint is Saved\n",
        "os.makedirs(\"character/class_data\", exist_ok=True) # Class Data for Prior Preservation Loss\n",
        "\n",
        "print(\"Folders Created Successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLGEsYvjaIRY",
        "outputId": "34aa68cf-a89b-4639-bfa0-c977073e4e60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders created: 'data' and 'checkpoint'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Optional use of wandb. If not using removing the argument during training"
      ],
      "metadata": {
        "id": "h-P_Lr4SWfei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "r4MOKOmNltLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd diffusers\n",
        "!pip install -e .\n",
        "!pip install -r examples/dreambooth/requirements.txt\n",
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "DB6QFxTib3Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Use config that fits your needs."
      ],
      "metadata": {
        "id": "D25jtL9MWYxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use config that is best for you\n",
        "!accelerate config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HHN_1Sq2uuN",
        "outputId": "6dc37b8c-fe34-4981-a202-ab2d35a7d4d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r----------------------------------------------------------------------------------------------------In which compute environment are you running?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mThis machine\u001b[0m\r\n",
            "    AWS (Amazon SageMaker)\n",
            "\u001b[2A\u001b[?25l0\n",
            "\u001b[32mThis machine\u001b[0m\n",
            "----------------------------------------------------------------------------------------------------Which type of machine are you using?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mNo distributed training\u001b[0m\n",
            "    multi-CPU\n",
            "    multi-XPU\n",
            "    multi-GPU\n",
            "    multi-NPU\n",
            "    multi-MLU\n",
            "    multi-MUSA\n",
            "    TPU\n",
            "\u001b[8A\u001b[?25l0\n",
            "\u001b[32mNo distributed training\u001b[0m\n",
            "\u001b[?25hDo you want to run your training on CPU only (even if a GPU / Apple Silicon / Ascend NPU device is available)? [yes/NO]:NO\n",
            "Do you wish to optimize your script with torch dynamo?[yes/NO]:NO\n",
            "Do you want to use DeepSpeed? [yes/NO]: NO\n",
            "What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:all\n",
            "Would you like to enable numa efficiency? (Currently only supported on NVIDIA hardware). [yes/NO]: NO\n",
            "----------------------------------------------------------------------------------------------------Do you wish to use mixed precision?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mno\u001b[0m\n",
            "    fp16\n",
            "    bf16\n",
            "    fp8\n",
            "\u001b[4A\u001b[?25l2\n",
            "\u001b[32mbf16\u001b[0m\n",
            "\u001b[?25haccelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Important Note: Prior to training with train_dreambooth_lora_sdxl.py you MUST go to line 1187 where the lora config is mentioned and delete the line indicating \"use dora\""
      ],
      "metadata": {
        "id": "4HqxFkgeVt-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py \\\n",
        "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\"  \\\n",
        "  --instance_data_dir=\"/content/character/data\" \\\n",
        "  --class_data_dir=\"/content/character/class_data\" \\\n",
        "  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n",
        "  --output_dir=\"/content/character/checkpoint\" \\\n",
        "  --mixed_precision=\"bf16\" \\\n",
        "  --with_prior_preservation \\\n",
        "  --instance_prompt=\"photo of sks character in a jacket\" \\\n",
        "  --class_prompt=\"photo of a character in modern cartoon style\" \\\n",
        "  --resolution=1024 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=600 \\\n",
        "  --validation_prompt=\"A photo of sks character\" \\\n",
        "  --validation_epochs=50 \\\n",
        "  --checkpointing_steps=100 \\\n",
        "  --use_8bit_adam \\\n",
        "  --report_to=\"wandb\" \\\n",
        "  --rank=8 \\\n",
        "  --seed=\"0\""
      ],
      "metadata": {
        "id": "qL69PwlIy6FZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}